import os
import torch
import hydra
import lightning as L
from omegaconf import DictConfig, OmegaConf
from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor
from lightning.pytorch.loggers import TensorBoardLogger

@hydra.main(config_path="configs", config_name="config", version_base="1.3.2")
def main(cfg: DictConfig):
    # 1. é’ˆå¯¹ 4090 çš„ç®—åŠ›ä¼˜åŒ–
    # æ˜¾è‘—æå‡ 3D å·ç§¯åœ¨ Tensor Cores ä¸Šçš„è¿è¡Œé€Ÿåº¦
    torch.set_float32_matmul_precision('high')
    
    # 2. è®¾ç½®éšæœºç§å­
    L.seed_everything(cfg.get("seed", 1337))

    # 3. å®ä¾‹åŒ– DataModule
    # ç¡®ä¿è·¯å¾„è¢« Hydra è½¬æ¢ä¸ºç»å¯¹è·¯å¾„ï¼Œé¿å…è·¯å¾„æ¼‚ç§»
    OmegaConf.set_struct(cfg, False)
    from hydra.utils import to_absolute_path
    cfg.data.path = to_absolute_path(cfg.data.path)
    
    datamodule = hydra.utils.instantiate(cfg.data)
    datamodule.setup(stage="fit")

    # 4. å®ä¾‹åŒ–æ¨¡å‹ç³»ç»Ÿ
    # è¿™é‡Œé€šè¿‡ hydra ä¼ å…¥ model é…ç½®ï¼ˆbaseline æˆ– fusionï¼‰
    model = hydra.utils.instantiate(cfg.model)
    from src.engine.pl_module import VesselSystem
    system = VesselSystem(model=model, cfg=cfg)

    # 5. é…ç½®æ—¥å¿—ä¸å›è°ƒ
    logger = TensorBoardLogger(save_dir="tb_logs", name=cfg.run_name)
    
    checkpoint_callback = ModelCheckpoint(
        dirpath=f"tb_logs/{cfg.run_name}/version_{logger.version}/checkpoints",
        filename="epoch={epoch}-step={step}",
        monitor="val/dice",
        mode="max",
        save_last=True,
        save_top_k=3
    )
    
    lr_monitor = LearningRateMonitor(logging_interval='step')

    # 6. åˆå§‹åŒ– Trainer
    # ä¿æŒ 8000 Steps ä»¥ç¡®ä¿ 36.3M å‚æ•°çš„ Fusion æ¨¡å‹èƒ½å……åˆ†æ”¶æ•›
    trainer = L.Trainer(
        max_steps=cfg.trainer.get("max_steps", 8000), 
        accelerator="gpu",
        devices=1,
        logger=logger,
        callbacks=[checkpoint_callback, lr_monitor],
        precision="16-mixed",  # ä½¿ç”¨æ··åˆç²¾åº¦èŠ‚çœ 4090 æ˜¾å­˜
        val_check_interval=cfg.trainer.get("val_check_interval", 1.0),
        log_every_n_steps=10
    )

# 1. æ‰‹åŠ¨è§¦å‘æ•°æ®å‡†å¤‡
    datamodule.setup(stage="fit")

    # 2. æ‰“å°ç¡®è®¤ï¼Œç¡®ä¿æ•°æ®æ²¡é—®é¢˜
    train_loader = datamodule.train_dataloader()
    val_loader = datamodule.val_dataloader()
    print(f"ğŸ“¦ [Data Check] Train batches: {len(train_loader)}, Val batches: {len(val_loader)}")

    # 3. ğŸš€ ç»ˆæä¿®å¤ï¼šä¸å†ä¼ é€’ datamodule å®ä¾‹ï¼Œç›´æ¥ä¼ é€’ loaders å…³é”®å­—å‚æ•°
    trainer.fit(
        model=system,
        train_dataloaders=train_loader,
        val_dataloaders=val_loader
    )

if __name__ == "__main__":
    main()